---
layout: post    
title: 数据结构与算法学习心得    
date: 2019-01-24    
tags: 数据结构与算法          
---

<br>
### 前言    
本文档主要是针对在学习和工作中对于数据结构与算法的感悟，主要包括以下内容常用的基础的数据结构与算法。其涉及到以下数据结构：数组、链、栈、队列、散列表、二叉树、堆、跳表、图、树等。涉及到的算法主要包括递归、排序、二分查找、搜索、哈希算法、分治算法、回溯算法、对台规划、字符串匹配算法等。     
对于此部分的学习不要死记硬背，要掌握分析的能力，抓住算法的特定，应用场景。用到的时候，能够想到即可，再花些时间弄懂即可。知识需要沉淀，不要想试图一下子掌握所有，学习知识的过程是反复迭代、不断沉淀的过程。



<br>
### 基础知识    
数据结构，就是一组数据的存储结构。算法，就是操作数据的一组方法。数据结构视为算法服务的，算法要作用于特定的数据结构。            
#### 复杂度分析      
数据结构和算法本身解决的是“快”和“省”的问题，即如何让代码运行得更快，如何让代码更省存储空间。所以，执行效率是算法一个非常重要的考量指标，其中主要使用的是时间和空间复杂度分析。    
##### 大O复杂度      
代码的执行时间T(n)与每行代码的执行次数n成正比，其表达式如下所示：    
```
T(n)=O(f(n))
```         
注释：   
* `T(n)`：表示代码的执行时间。    
* `n`：表示数据规模的大小。          
* `f(n)`：表示每行代码执行次数的总和。    
* `O`：表示代码的执行时间T(n)与f(n)成正比。    

大O时间复杂度，并非代码执行时间，而是表示代码执行时间随数据规模增长的变化趋势，所以，也叫作**渐进时间复杂度**，简称**时间复杂度**。其表示法，指出了最糟糕情况下的运行时间。    

##### 时间复杂度分析    
1. 只关注循环次数最多的一段代码。由于大O表示法只是表示一种变化趋势，因此会忽略掉公式中的常量、低级、系数。  
2. 将所有复杂度相加，总复杂度等于量级最大的那段代码复杂度。    
3. 对于嵌套代码的复杂度等于嵌套内外代码复杂度的乘积。    
4. 对于多规模要求多个规模复杂度之和。    

##### 常见时间复杂度分析     
###### 以下将列举几种常见时间复杂度量级，按数量级递增     
* 常量阶：O(1)    
* 对数阶：O(logn)    
* 线性阶：O(n)    
* 线性对数阶：O(nlongn)    
* 平方阶：O(n^2)、立方阶阶O(n^3)...K次方阶O(n^k)    
* 指数阶：O(2^n)    
* 阶乘阶：O(n!)    

###### 常见的复杂度级别     
**多项式阶**：随着数据规模的增长，算法的执行时间和空间占用，按照多项式的比例增长。其中常见的如下所示
> 1. O(1)：只要代码的时间复杂度不随n的增长而增长，这样代码的时间复杂度表示常量级。        
> 2. O(log n)、O(n*log n)：不管以2为底、以3为底、还是以10为底，都把所有对数阶的时间复杂度记为O(log n)，因为对数之间可以相互转化，`log3^n =log3^2 * log2^n`，所以O(log3^n)=O(C*logn)，其中C=log3^2是一个常量，忽略此系数。    
> 3. O(m+n)：对于无法评估的m和n两个数据规模，要用此方法表示。  

##### 空间复杂度分析    
空间复杂度全称为渐进空间复杂度，表示算法的存储空间与数据规模之间的增长关系。    
        

<br>
### 常见数据结构    
#### 数组    
数组（Array）是一种线性表数据结构，它用一组连续的内存空间，来存储一组具有相同类型的数据。    
数组支持随机访问，根据下标随机访问的时间复杂度为O(1)。    
##### 改善数组低效的“插入”和“删除”    
* 当数组中存储的数据没有任何规律，数组只是当做一个存储数据的集合，侧可以直接将数组插入第K个位置，为了避免大规模数据搬移，可以将原来k位置的数据摆一道数组元素的最后。    
* 在默写场景下，并非要数组中数据连续性，这是可以考虑将多次删除操作集中在一起执行，从而每次删除操作并不是真正的搬移数据，而是记录数据已经被删除，当数组没有更大空间存储数据时，才触发一次真正的删除操作，这样可以大大减少删除操作导致的数据搬移。    
* 总结，不要去死记硬背某个数据结构或者算法，要学习它背后的思想和处理技巧，这些东西才是最有价值的。    

##### 用数组比高级数组更合适场景    
1. Java ArrayList无法存储基本类型，例如int、long，需要封装为Integer、Long类型，而Autoboxing、Unboxing则有一定的性能消耗，若是特别关注性能，或是希望使用基本类型，就可以选用数组。    
2. 数组大小事先已知，并且对数组的操作非常简单，用不到ArrayList提供的大部分用法，也可以直接使用数组。    
3. 多维数组用数组更加直观。    

##### 数组寻址公式    
* 一维数组寻址公式：    
> a[k]_address = base_address + k * type_size    


* 二位数组寻址公式m*n数组：    
> a[i][j]_address = base_address +(i * n + j) * type_size    

#### 链表    
链表不需要一块连续的内存空间，它通过“指针”将一组零散的内存块串联起来使用。    
常见的链表结构为：单链表、双向链表、循环链表。    
##### 链表实际用法    
在实际软件开发中，从链表中删除一个数据基本有两种情况：    
* 删除节点中“只等于某个定值”的节点。    
> 单纯的删除操作时间复杂度为O(1)，但是遍历查找的时间为主要的耗时点，对应的时间复杂度为O(n)，根据时间复杂度分析中加法法则，删除等于给定值节点对应的链表操作的总时间复杂度为O(n)。    


* 删除给定指针的节点。    
> 已知要删除的节点，需找到此节点的前驱节点，单向链表需要从链表头开始找，此时时间复杂度为O(n)，对于双向链表直接可以取得，此时时间复杂度为O(1)。     

##### 链表代码书写常用技巧        
优雅的写出链表代码5大技巧：    

###### 理解指针或引用的含义    
将某个变量赋值给指针，实际上就是将这个变量的地址赋值给指针，或者反过来说，指针中存储了这个变量的内存地址，指向了这个变量，通过指针就能找到这个变量。    

###### 警惕指针丢失和内存泄漏（单链表）    
关键为将拆分的数据，挂载到已知变量。    

###### 利用“哨兵”简化实现难度    
链表中的“哨兵”节点是解决边界问题，不参与业务逻辑。    

###### 重点留意边界条件处理    
对于边界处理方面，需要常问下面4个问题：    
1. 如果链表为空时，代码是否能正常工作？    
2. 如果链表只包含一个节点时，代码是否能正常工作？    
3. 如果链表只包含两个节点时，代码是否能正常工作？    
4. 代码逻辑在处理头尾节点时是否能正常工作？    

###### 举例画图，辅助思考    
核心思想：释放脑容量，留更多的给逻辑思考，产生一个清晰思路。    

#### 栈        
从栈的操作特性上来看，栈是一种“操作受限”的线性表，只运行在一段插入和删除数据。相比于数组和链表，栈带给我们的只有限制，并没有任何优势，那我们直接使用数组或链表不就好了吗？为什么还要用这个“操作受限”的“栈”呢？    
> 事实上，从功能上来说，数组或链表确实可以替代栈，但是，特定的**数据结构是对特定场景的抽象**，而且，数组或链表暴露了太多的操作接口，操作上的确灵活自由，但使用时就比较不可控，自然也容易出错。     

##### 什么场景下使用栈    
当某个数据集合只涉及在一端插入和删除数据，并且满足后进先出、先进后出的特性，此时首选“栈”这种数据结构。    

##### 栈复杂度    
不管是顺序栈还是链式栈，存储数据只需要一个大小为n的数组就够了。在入栈和出栈过程中，只需要一两个临时变量存储空间，所以空间复杂度是O(1)，注意，这里存储数据需要一个大小为n的数组，并不是说空间复杂度就是O(n)。因为，这n个空间必须的，无法省掉。所以我们说空间复杂度的时候，是指出了原本的数据存储空间外，算法运行还需要额外的存储空间。    
不管顺序栈还是链式栈，入栈、出栈只涉及栈顶个别数据的操作，所以时间复杂度都是O(1)。        
    
#### 队列     
队列的核心特点是先进先出，也是一种操作受限的线性表数据结构。    

##### 队列应用场景                    
队列作为基础的数据结构，其应用也很广泛，特别是一些特有某些额外特性的队列，比如循环队列，阻塞队列，并发队列。他们在很多底层系统、框架、中间件的开发中，起着关键性的作用。比如高性能队列Disruptor、Linux环形缓存，都用到了循环并发队列；Java concurrent并发包利用ArrayBlockingQueue来实现公平锁等。    

##### 阻塞队列    
阻塞队列，其实就是队列基础上增加了阻塞操作。就是在队列为空时，从队头取数据会被阻塞。因为此时没有数据可取，直到队列中有了数据才能返回；如果队列已满，那么插入数据的操作就会被阻塞，直到队列中空闲位置后再插入数据，然后再返回。例如“生产者-消费者模型”  ，这种基于阻塞队列实现的“生产者-消费者模型” ，可以有效地协调生产和消费的速度。    

##### 并发队列    
线程安全的队列叫并发队列，实现方式是直接在`enqueue()`、`dequeue()`方法上加锁，但是锁粒度大并发度会比较低，同一时刻仅允许一个存或取操作。实际上，基于数组的循环队列，利用CAS原子操作，可以实现非常高效的并发队列。      

##### 队列应用举例           
对于大部分资源有限的场景，当没有空闲资源时，基本上可以通过“队列”这种数据结构来实现请求排队。     
###### 线程池中没有空闲线程时，如何处理    
一般情况有两种处理策略，第一种为非阻塞的处理方式，直接拒绝任务；另一种是阻塞的处理方式，将请求排队，等到有空闲线程时，取出排队的请求继续处理。    
为了达到公平地处理每一个排队的请求，先进者先服务，所以队列这种数据结构很适合来存储排队请求。
采用哪种队列存储也有两种方式。第一种，基于链表的实现方式，可以实现一个支持无限排队的无界队列，但是可能会导致过多的请求排队等待，请求处理的响应时间过长，所以，针对响应时间比较敏感的系统，基于链表实现的无限排队的线程池是不合适的。第二种，基于数组实现的有界队列，队列的大小有限，所以线程池中排队的请求超过队列大小时，接下来的请求就会被拒绝，这种方式对响应时间敏感的系统来说，就相对更合理。不过设置一个合理的队列大小，也是非常有讲究的，队列太大导致等待的请求太多，队列太小会导致无法充分利用系统资源，发挥最大性能。    
**总结**：对于如何设计解决方法，先要分析业务中基本需求和特点，选择合适的数据结构，随后分析此类数据结构有几种实现方式，每种实现方式具有那些优点和缺点，平衡自己业务需求，进行最终选择。        
 
<br>
### 核心算法        
#### 递归    
##### 什么是递归    
> 1. 递归是一种非常高效、简洁的编码技巧、一种应用非常广泛的算法，比如DFS深度优先搜索、前中后序二叉树遍历等。    
> 2. 方法或函数调用自身的方式称为递归，调用称为递，返回称为归。    
> 3. 基本上，所有的递归问题都可以用递推公式来表示，比如:    
>   * `f(n) = f(n-1) + 1`    
>   * `f(n) = f(n-1) + f(n-2)`    
>   * `f(n) = n*f(n-1)`    

##### 递归优缺点    
> * 优点：代码的表达力很强，简洁。    
> * 缺点：空间复杂度高、有栈溢出风险、存在重复计算、过多的函数调用会耗时较多等问题。    

##### 什么样的问题采用递归解决    
> 一个问题只要同时满足一下3个条件，就可以用递归来解决：    
>  1. 问题的解可以分解为几个子问题的解。    
>  2. 问题和分解后的子问题，除了数据规模不同，求解思路完全一样。   
>  3. 存在递归终止条件。    

##### 如何实现递归    
> 1. 递归代码编写    
> 写递归代码的关键就是找到如何将大问题分解为小问题的规则，并且基于此写出递推公式，然后再推敲终止条件，最后将递推公式和终止条件转化为代码。    
> 2. 递归代码理解    
> 对于递归代码，若试图想清楚整个递和归的过程，实际上是进入一个思维误区，而具体做法为，如果一个问题A可以分解为若干个子问题B、C、D，可以假设子问题B、C、D已经解决。而且，只需要思考问题A和子问题B、C、D两层之间的关系即可，不需要一层层往下思考子问题与子子问题，子子问题与子子子问题之间的关系。屏蔽掉递归细节，这样理解起来就简单多了。    
> 因此，理解递归代码，就把它抽象成一个递推公式，不用想一层层的调用关系，不要试图用人脑去分解递归的每个步骤。    

##### 递归常见问题及解决方案    
> * 警惕堆栈溢出：可以声明一个全局变量来控制递归的深度，从而避免堆栈溢出。     
> * 警惕重复计算：通过某种数据结构来保存已求解过的值，例如`hash`，从而避免重复计算。    

##### 将递归转为非递归    
> 基本上所有递归代码都可改为迭代循环的非递归写法。主要方式为：抽象递推公式，初始值和边界条件，然后用迭代循环实现。    


#### 排序    
##### 经典排序    
> 最经典与常见的排序算法为：冒泡排序、插入排序、选择排序、快速排序、归并排序、计数排序、基数排序、桶排序。    
> * 冒泡排序、插入排序、选择排序： 时间复杂度为O(n^2)，基于比较排序。    
> * 快速排序、归并排序： 时间复杂度为O(nlogn)，基于比较排序。    
> * 计数排序、基数排序、通排序: 时间复杂度为O(n)，不基于比较排序。    

##### 如何分析一个排序算法    
> * 排序算法的执行效率。    
>   1. 最好情况、最坏情况、平均情况时间复杂度。有序度不同的数据，对于排序的执行时间肯定是有影响的，因此要知道排序算法在不同数据下的性能表现。        
>   2，时间复杂度的系数、常数、低阶。从实际软件开发中考虑，基本排序都是规模比较小的数据。    
>   3. 比较次数和交换（或移动）次数。以及比较的排序算法，会涉及两种操作，比较和交换或移动，分析执行效率时，应当考虑。    
> * 排序算法的内存消耗。
>   1. 原地排序算法，就是特质空间复杂度是O(1)的排序算法，即不用耗费额外的内存进行存储。    
> * 排序算法的稳定性。    
>   1. 稳定性，指待排序的序列中存在值相等的元素，经过排序之后，相等元素之间原有的先后顺序不变。    

##### 冒泡排序    

###### 冒泡排序执行过程    
> 冒泡排序只会操作相邻的两个数据。每次冒泡操作都会对相邻的两个元素进行比较，看是否满足大小关系要求，如果不满足就让他俩互换。一次冒泡会让至少一个元素移动到它应该在的位置，重复n次，就会完成了n个数据的排序工作。        

###### 冒泡优化方式     
> **优化**：当某次冒泡操作已经没有数据交换时，说明已经达到完全有序，不用再继续执行后续的冒泡操作。     

###### 冒泡分析    
> 1. 是原地排序算法吗？    
>   冒泡过程只涉及相邻数据的交互操作，没有申请格外的临时空间，空间复杂度为O(1)，因此是原地排序算法。    
> 2. 是稳定的排序算法吗？    
>   只有交互才改变两个元素的前后顺序，当相等的时候，不做交互，相同大小的数据在排序前后不会改变顺序，因此是稳定的排序算法。    
> 3. 时间复杂度是多少？    
>   * 最好时间复杂度：顺序排列，只需要进行一次冒泡操作，就可以结束，O(n)。    
>   * 最坏时间复杂度：逆序排列，需要进行n次冒泡操作，O(n^2)。    
>   * 平均时间复杂度：加权平均期望时间复杂度为O（n^2）    

###### 冒泡平均时间复杂度    
> 通过有序度和逆序度来分析平均时间复杂度。    
> * 有序度是数组中具有有序关系的元素对的个数。其数学表达式为：`a[i] <= a[j], 且 i < j`    
>   例如：对于一个倒序排列的数组，`6、5、4、3、2、1`，有序度为0；对于一个完全有序的数组，比如`1、2、3、4、5、6`，有序度就是`n*(n-1)/2`，也就是15，此为满有序度。    
> * 逆有序度的定义与有序度相反（从小到大为有序），`a[i] > a[j],且 i < j`。    
> * 核心公式： `逆虚度 = 满有序度 - 有序度`。    

> 冒泡排序包含两个操作原子，**比较**和**交换**。每交换一次，有序度就加1。不管算法怎么改进，交换次数总是确定的，为**逆序度，也就是`n*(n-1)/2-初始有序度`**。             

> 对于包含n个数据的数组进行冒泡排序，平均交换次数是多少？    
> * 最坏情况下，初始状态为有序度为0，所以要进行`n*(n-1)/2`次交换（减少逆序度）。    
> * 最好情况下，初始状态的有序度是`n*(n-1)/2`，就不需要进行交换。    
> * 平均情况下，表示不高也不低的平均状况需要`n*(n-1)/4`次交换操作，比较操作肯定要比交换操作多，而复杂度的上限是O(n^2)，所以平均情况下的实际复杂度为O(n^2)。    

##### 插入排序    

###### 插入排序执行过程         

<br>
参考链接：    

<br> 
转载请注明：[HunterYuan的博客](https://clodfisher.github.io/) » [数据结构与算法学习心得](https://clodfisher.github.io/2019/01/StructuresAndAlgorithms/)            